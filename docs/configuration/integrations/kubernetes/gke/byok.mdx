---
title: "Bring Your Own GKE Cluster (BYOK)"
description: "Connect your existing Google GKE cluster to Qovery"
---

## Overview

Bring Your Own Kubernetes (BYOK) allows you to connect your existing GKE cluster to Qovery. You maintain full control over your cluster while Qovery manages application deployments.

## Prerequisites

<Check>Existing GKE cluster (Kubernetes 1.24+)</Check>
<Check>kubectl access with cluster-admin permissions</Check>
<Check>GCP service account for Qovery</Check>
<Check>Compute Engine persistent disk CSI driver installed</Check>
<Check>Load Balancer Controller or Nginx Ingress</Check>

## Setup

<Steps>
  <Step title="Get Qovery Agent Manifests">
    In Qovery Console:
    1. Settings → Clusters → Add Cluster
    2. Select "Bring Your Own Kubernetes"
    3. Choose "Google GKE"
    4. Download Helm values or kubectl manifests
  </Step>

  <Step title="Install Qovery Agent">
    Using Helm (recommended):
    ```bash
    helm repo add qovery https://helm.qovery.com
    helm repo update

    helm install qovery-agent qovery/qovery-agent \
      --namespace qovery \
      --create-namespace \
      --values qovery-values.yaml
    ```

    Or using kubectl:
    ```bash
    kubectl apply -f qovery-agent.yaml
    ```
  </Step>

  <Step title="Verify Connection">
    Check agent status:
    ```bash
    kubectl get pods -n qovery
    # qovery-agent-* should be Running
    ```

    In Qovery Console, cluster should show as "Connected"
  </Step>

  <Step title="Deploy Applications">
    Start deploying applications to your BYOK cluster
  </Step>
</Steps>

## What Qovery Installs

**Qovery Agent**:
- Manages application deployments
- Communicates with Qovery Control Plane
- Handles secrets and configuration

**Optional Components** (if not present):
- Nginx Ingress Controller
- Cert-Manager (for SSL certificates)
- External-DNS (for domain management)
- Metrics Server

## Requirements

### Kubernetes Version

- Minimum: 1.24
- Recommended: 1.27+
- Maximum: 1.29

### Required Addons

<Tabs>
  <Tab title="Storage">
    **Compute Persistent Disk CSI Driver**:

    GKE clusters have this enabled by default. Verify:
    ```bash
    kubectl get csidriver pd.csi.storage.gke.io
    ```

    **Storage Class**:
    ```yaml
    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
      name: pd-ssd
      annotations:
        storageclass.kubernetes.io/is-default-class: "true"
    provisioner: pd.csi.storage.gke.io
    parameters:
      type: pd-ssd
      replication-type: regional-pd
    ```
  </Tab>

  <Tab title="Load Balancer">
    **GCE Ingress** (default for GKE):
    ```yaml
    apiVersion: networking.k8s.io/v1
    kind: IngressClass
    metadata:
      name: gce
      annotations:
        ingressclass.kubernetes.io/is-default-class: "true"
    spec:
      controller: k8s.io/ingress-gce
    ```

    **Or Nginx Ingress Controller**:
    ```bash
    helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
    helm install nginx-ingress ingress-nginx/ingress-nginx \
      --set controller.service.type=LoadBalancer
    ```
  </Tab>

  <Tab title="Metrics">
    **Metrics Server**:

    Usually pre-installed on GKE. Verify:
    ```bash
    kubectl top nodes
    ```

    If not installed:
    ```bash
    kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
    ```
  </Tab>
</Tabs>

### IAM Permissions

Qovery needs GCP IAM permissions for:
- Creating/managing Load Balancers
- Managing Cloud DNS records (if using)
- Google Container Registry access (if using GCR)

Example service account roles:
- `roles/compute.loadBalancerAdmin`
- `roles/dns.admin`
- `roles/storage.objectViewer` (for GCR)

```bash
# Create service account for Qovery
gcloud iam service-accounts create qovery-agent \
  --display-name="Qovery Agent"

# Grant necessary roles
gcloud projects add-iam-policy-binding PROJECT_ID \
  --member="serviceAccount:qovery-agent@PROJECT_ID.iam.gserviceaccount.com" \
  --role="roles/compute.loadBalancerAdmin"

gcloud projects add-iam-policy-binding PROJECT_ID \
  --member="serviceAccount:qovery-agent@PROJECT_ID.iam.gserviceaccount.com" \
  --role="roles/dns.admin"
```

## Cluster Configuration

### Resource Requirements

**Minimum**:
- 2 nodes (e2-medium or larger)
- 4 vCPUs total
- 8 GB RAM total

**Recommended**:
- 3+ nodes across multiple zones
- Auto-scaling enabled
- Mix of standard and preemptible VMs

### Networking

**VPC Requirements**:
- VPC-native cluster (alias IPs)
- Private nodes (recommended)
- Cloud NAT or Proxy for outbound traffic
- Firewall rules for ingress traffic

**Node Access**:
- Private nodes with Cloud NAT (recommended)
- Public nodes (for dev/test only)
- Authorized networks for control plane access

### DNS Configuration

**Option 1**: External-DNS (automated)
```bash
helm install external-dns bitnami/external-dns \
  --set provider=google \
  --set google.project=YOUR_PROJECT_ID \
  --set txtOwnerId=my-cluster
```

**Option 2**: Manual DNS management
- Create Cloud DNS records manually for each application
- Point to load balancer IP address

## Best Practices

<CardGroup cols={2}>
  <Card title="Separate Namespaces" icon="folder-tree">
    - Use dedicated namespace for Qovery (`qovery`)
    - Separate namespaces per environment
    - Apply resource quotas
    - Network policies for isolation
  </Card>

  <Card title="Access Control" icon="key">
    - Create dedicated service account for Qovery
    - Use RBAC for least privilege
    - Workload Identity for pod authentication
    - Rotate credentials regularly
  </Card>

  <Card title="High Availability" icon="shield">
    - Multi-zone node distribution
    - Regional persistent disks
    - Pod disruption budgets
    - Regular backups
  </Card>

  <Card title="Monitoring" icon="chart-line">
    - Enable GKE monitoring and logging
    - Set up alerts for Qovery agent
    - Monitor cluster resource usage
    - Track application health
  </Card>
</CardGroup>

## Troubleshooting

<AccordionGroup>
  <Accordion title="Agent Not Connecting">
    **Solutions**:
    - Verify agent pods are running: `kubectl get pods -n qovery`
    - Check agent logs: `kubectl logs -n qovery -l app=qovery-agent`
    - Ensure outbound internet access (Cloud NAT configured)
    - Verify API token is correct
    - Check firewall rules
  </Accordion>

  <Accordion title="Deployments Failing">
    **Solutions**:
    - Check node capacity and resources
    - Verify storage class exists and works
    - Ensure ingress controller is working
    - Check for network policy blocking traffic
    - Review GKE logs in Cloud Logging
  </Accordion>

  <Accordion title="Load Balancers Not Creating">
    **Solutions**:
    - Verify IAM permissions for load balancer creation
    - Check firewall rules allow health checks
    - Ensure service account has proper bindings
    - Review GCE Ingress controller logs
    - Check VPC firewall rules
  </Accordion>
</AccordionGroup>

## Next Steps

<CardGroup cols={2}>
  <Card title="Deploy Application" icon="rocket" href="/getting-started/guides/getting-started/deploy-your-first-application">
    Deploy your first application
  </Card>

  <Card title="Cluster Configuration" icon="sliders" href="/configuration/clusters">
    Configure cluster settings
  </Card>

  <Card title="Qovery-Managed GKE" icon="wand-magic-sparkles" href="/configuration/integrations/kubernetes/gke/managed">
    Consider Qovery-managed for easier management
  </Card>

  <Card title="Kubernetes Documentation" icon="book" href="/configuration/integrations/kubernetes/byok">
    Generic Kubernetes BYOK guide
  </Card>
</CardGroup>
