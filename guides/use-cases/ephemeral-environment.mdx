---
title: "Ephemeral Environments"
description: "Create on-demand temporary environments for development, testing, and E2E testing with automated CI/CD workflows"
---

## Overview

Ephemeral environments are temporary, isolated environments that are automatically created for specific purposes (like feature development or testing) and destroyed when no longer needed. They provide developers with production-like environments without the cost and complexity of maintaining permanent infrastructure.

Qovery offers **two approaches** to create and manage ephemeral environments, depending on your team's needs and technical requirements.

## Two Ways to Create Ephemeral Environments

<CardGroup cols={2}>
  <Card title="Simple Approach" icon="bolt">
    **Fully Automated Preview Environments**

    Turn on auto-preview environment feature in Qovery and let it handle everything automatically.

    - Zero configuration required
    - Instant setup (enable and go)
    - Automatic creation/destruction
    - Perfect for quick feedback
    - Best for teams wanting simplicity
  </Card>

  <Card title="Advanced Approach" icon="code">
    **Custom CI/CD Integration**

    Integrate ephemeral environments into your existing CI/CD pipeline for complete control.

    - Full workflow customization
    - E2E testing automation
    - Custom creation/deletion logic
    - Integration with GitHub Actions, GitLab CI, etc.
    - Best for advanced testing scenarios
  </Card>
</CardGroup>

## Benefits of Ephemeral Environments

<CardGroup cols={3}>
  <Card title="Faster Development" icon="rocket">
    Test changes in isolation without affecting other developers
  </Card>

  <Card title="Cost Savings" icon="dollar-sign">
    Pay only for environments when they're in use
  </Card>

  <Card title="Improved Testing" icon="flask">
    Test in production-like environments before deployment
  </Card>

  <Card title="Better Collaboration" icon="users">
    Stakeholders can review changes in live environments
  </Card>

  <Card title="Reduced Risk" icon="shield">
    Catch issues early before they reach production
  </Card>

  <Card title="Faster Feedback" icon="comments">
    Get immediate feedback from team members and stakeholders
  </Card>
</CardGroup>

---

## Approach 1: Simple Automated Preview Environments

The simplest way to get started with ephemeral environments is to enable Qovery's built-in preview environment feature. This requires minimal configuration and provides instant results.

### How It Works

<Steps>
  <Step title="Enable Preview Environments">
    Navigate to your Environment settings in the Qovery Console and enable "Preview Environments"

    **Configuration Options**:
    - Trigger on pull request creation
    - Trigger on branch push
    - Auto-delete on PR close/merge
    - Set lifecycle timeout (e.g., 7 days)
  </Step>

  <Step title="Qovery Handles Everything">
    Once enabled, Qovery automatically:
    - Creates a new environment for each pull request
    - Deploys your application with the PR changes
    - Generates a unique URL for the environment
    - Updates the environment on each new commit
    - Destroys the environment when the PR is closed
  </Step>

  <Step title="Get Instant Feedback">
    Team members and stakeholders can access the live environment via the generated URL to review changes before merging
  </Step>
</Steps>

### Basic Configuration

**Via Qovery Console**:
1. Navigate to Environment settings
2. Enable "Preview Environments"
3. Configure triggers (PR creation, branch push)
4. Set lifecycle policies (auto-delete after X days)

**Via Configuration**:
```yaml
# Application configuration
applications:
  - name: web-app
    git:
      repo: https://github.com/org/repo
      branch: main
    preview_environments:
      enabled: true
      triggers:
        - pull_request
      lifecycle:
        auto_delete_on_close: true
        auto_delete_after: 7d
        auto_stop_after: 24h
```

### Environment Variables

```yaml
environment_variables:
  - name: APP_ENV
    value: preview
  - name: DATABASE_URL
    value_from_secret: PREVIEW_DB_URL
  - name: PREVIEW_MODE
    value: "true"
```

### Resource Configuration

For preview environments, you typically want smaller resource allocations:

```yaml
resources:
  requests:
    cpu: 500m
    memory: 1Gi
  limits:
    cpu: 1000m
    memory: 2Gi
instances:
  min: 1
  max: 2
```

### Database Strategy

<Tabs>
  <Tab title="Shared Database">
    **Pros**: Lower cost, faster creation
    **Cons**: Risk of data conflicts

    ```yaml
    # Use a single shared database
    # Isolate data using prefixes or schemas
    environment_variables:
      - name: DB_SCHEMA_PREFIX
        value: ${QOVERY_ENVIRONMENT_NAME}
    ```
  </Tab>

  <Tab title="Isolated Database">
    **Pros**: Complete isolation, better for testing migrations
    **Cons**: Higher cost, slower creation

    ```yaml
    databases:
      - name: preview-db
        type: postgresql
        version: "15"
        mode: CONTAINER  # Lightweight for preview
        storage: 10GB
        lifecycle:
          delete_on_environment_delete: true
    ```
  </Tab>

  <Tab title="Database Snapshot">
    **Pros**: Realistic data, best balance
    **Cons**: Moderate cost and creation time

    ```bash
    # Clone from production snapshot (sanitized)
    qovery database clone \
      --from production-db \
      --to preview-db \
      --sanitize-pii
    ```
  </Tab>
</Tabs>

### Database Seeding

Once your ephemeral environment is created, you'll typically need to populate it with test data. Qovery provides multiple approaches for database seeding.

<Tabs>
  <Tab title="Lifecycle Jobs">
    **Use Qovery Lifecycle Jobs** to automatically seed data after environment creation.

    **Step 1: Create a Dockerfile for your seed job**:

    ```dockerfile
    # Dockerfile.seed
    FROM node:18-alpine

    WORKDIR /app

    # Install PostgreSQL client for database readiness check
    RUN apk add --no-cache postgresql-client

    # Copy your seed scripts
    COPY package*.json ./
    COPY db/ ./db/
    COPY migrations/ ./migrations/

    # Install dependencies
    RUN npm ci --only=production

    # Create the seed script
    COPY seed.sh /seed.sh
    RUN chmod +x /seed.sh

    ENTRYPOINT ["/seed.sh"]
    ```

    **Step 2: Create the seed script**:

    ```bash
    #!/bin/sh
    # seed.sh

    echo "Waiting for database to be ready..."
    while ! pg_isready -h $DATABASE_HOST -U $DATABASE_USER; do
      sleep 2
      echo "Waiting..."
    done

    echo "Database is ready!"

    echo "Running migrations..."
    npm run db:migrate

    echo "Seeding database..."
    npm run db:seed

    echo "Seeding completed successfully!"
    ```

    **Step 3: Create a Lifecycle Job in Qovery Console**:
    1. Navigate to your Environment
    2. Click "Add Service" → "Lifecycle Job"
    3. Configure the job:
       - **Name**: `seed-database`
       - **Image**: `your-registry/seed-job:latest`
       - **Event**: `START` (runs when environment starts)
       - **Environment Variables**: Add `DATABASE_URL` (from secret)
       - **Resources**: 500m CPU, 512Mi Memory

    **Benefits**:
    - Automatic execution on environment creation
    - Integrated with Qovery's lifecycle management
    - Runs before application starts
    - Logs available in Qovery Console
  </Tab>

  <Tab title="CI/CD Pipeline">
    **Seed via your CI/CD pipeline** during environment creation:

    ```yaml
    # GitHub Actions example
    - name: Wait for Database
      run: |
        echo "Waiting for database to be ready..."
        for i in {1..30}; do
          if qovery application list --environment pr-${{ github.event.number }} | grep -q "RUNNING"; then
            break
          fi
          sleep 10
        done

    - name: Get Database Connection
      id: get-db
      env:
        QOVERY_API_TOKEN: ${{ secrets.QOVERY_API_TOKEN }}
      run: |
        ENV_NAME="pr-${{ github.event.number }}"
        DB_URL=$(qovery database get --environment $ENV_NAME --output json | jq -r '.url')
        echo "database_url=$DB_URL" >> $GITHUB_OUTPUT

    - name: Run Migrations
      env:
        DATABASE_URL: ${{ steps.get-db.outputs.database_url }}
      run: |
        npm run db:migrate

    - name: Seed Test Data
      env:
        DATABASE_URL: ${{ steps.get-db.outputs.database_url }}
      run: |
        npm run db:seed:test
    ```

    **Benefits**:
    - Full control over seeding process
    - Can run different seeds based on PR labels
    - Easy to debug in CI/CD logs
    - Can fail the workflow if seeding fails
  </Tab>

  <Tab title="Application Startup">
    **Seed on application startup** using initialization code:

    ```javascript
    // Node.js example - server.js
    const express = require('express');
    const { seedDatabase } = require('./db/seed');

    const app = express();

    async function startServer() {
      // Check if seeding is needed
      if (process.env.APP_ENV === 'preview' || process.env.AUTO_SEED === 'true') {
        console.log('Running database migrations...');
        await runMigrations();

        console.log('Seeding database...');
        await seedDatabase();

        console.log('Database ready!');
      }

      app.listen(3000, () => {
        console.log('Server running on port 3000');
      });
    }

    startServer().catch(console.error);
    ```

    **Benefits**:
    - No additional infrastructure needed
    - Guaranteed to run before app serves requests
    - Simple for small applications
    - Works across all platforms
  </Tab>

  <Tab title="Clone Production Data">
    **Clone sanitized production data** for realistic testing:

    ```bash
    # Clone and sanitize production database
    qovery database clone \
      --from production-db \
      --to pr-123-db \
      --sanitize-pii

    # Or using API
    curl -X POST "https://api.qovery.com/database/$PROD_DB_ID/clone" \
      -H "Authorization: Token $QOVERY_API_TOKEN" \
      -H "Content-Type: application/json" \
      -d '{
        "name": "pr-123-db",
        "environment_id": "'$PREVIEW_ENV_ID'",
        "sanitize": true
      }'
    ```

    **PII Sanitization Options**:
    ```sql
    -- Example sanitization script
    UPDATE users
    SET
      email = CONCAT('user-', id, '@example.com'),
      phone = CONCAT('+1555', LPAD(id::text, 7, '0')),
      first_name = 'Test',
      last_name = CONCAT('User', id),
      address = '123 Test Street',
      ssn = NULL,
      credit_card = NULL;

    UPDATE orders
    SET
      billing_address = '123 Test Street',
      shipping_address = '123 Test Street';
    ```

    **Benefits**:
    - Realistic data volumes and patterns
    - Test with production-like scenarios
    - Catch edge cases early
    - Better for performance testing
  </Tab>
</Tabs>

### Seeding Strategies

<AccordionGroup>
  <Accordion title="Minimal Seed Data" icon="seedling">
    **Best for**: Unit tests, fast feedback, low resource usage

    ```javascript
    // seed-minimal.js
    async function seedMinimal() {
      // Create just enough data to run the application
      await createUser({ email: 'test@example.com', role: 'admin' });
      await createUser({ email: 'user@example.com', role: 'user' });

      // Minimal product catalog
      await createProduct({ name: 'Test Product 1', price: 10.00 });
      await createProduct({ name: 'Test Product 2', price: 20.00 });

      console.log('Minimal seed completed: 2 users, 2 products');
    }
    ```

    **Characteristics**:
    - 10-100 records total
    - Seeds in under 5 seconds
    - Minimal storage requirements
    - Good for development and quick tests
  </Accordion>

  <Accordion title="Representative Seed Data" icon="database">
    **Best for**: Integration tests, QA testing, demos

    ```javascript
    // seed-representative.js
    async function seedRepresentative() {
      // Create realistic user base
      const users = await createUsers(100);

      // Create product catalog
      const products = await createProducts(50);

      // Create orders with realistic patterns
      for (let i = 0; i < 500; i++) {
        const user = users[Math.floor(Math.random() * users.length)];
        const product = products[Math.floor(Math.random() * products.length)];

        await createOrder({
          userId: user.id,
          productId: product.id,
          quantity: Math.floor(Math.random() * 5) + 1,
          createdAt: randomDateInPast(90) // Last 90 days
        });
      }

      console.log('Representative seed completed: 100 users, 50 products, 500 orders');
    }
    ```

    **Characteristics**:
    - 1,000-10,000 records
    - Seeds in 30-60 seconds
    - Represents real-world distribution
    - Good for realistic testing
  </Accordion>

  <Accordion title="Large-Scale Seed Data" icon="chart-simple">
    **Best for**: Performance testing, load testing, stress testing

    ```javascript
    // seed-large-scale.js
    async function seedLargeScale() {
      console.log('Creating large-scale seed data...');

      // Batch insert for performance
      const batchSize = 1000;

      // Create 10k users in batches
      for (let i = 0; i < 10; i++) {
        await createUserBatch(batchSize);
      }

      // Create 5k products
      for (let i = 0; i < 5; i++) {
        await createProductBatch(batchSize);
      }

      // Create 100k orders
      for (let i = 0; i < 100; i++) {
        await createOrderBatch(batchSize);
      }

      console.log('Large-scale seed completed: 10k users, 5k products, 100k orders');
    }
    ```

    **Characteristics**:
    - 100,000+ records
    - Seeds in 5-15 minutes
    - Realistic performance characteristics
    - Good for load and stress testing
  </Accordion>

  <Accordion title="Scenario-Based Seeding" icon="list-check">
    **Best for**: E2E testing, specific feature testing

    ```javascript
    // seed-scenarios.js
    async function seedScenarios() {
      // Scenario 1: New user signup flow
      await createScenario({
        name: 'new-user-signup',
        setup: async () => {
          // Empty cart, no order history
          return await createUser({ email: 'newuser@example.com' });
        }
      });

      // Scenario 2: Returning customer with history
      await createScenario({
        name: 'returning-customer',
        setup: async () => {
          const user = await createUser({ email: 'returning@example.com' });
          await createOrderHistory(user.id, 5); // 5 past orders
          await createCart(user.id, 3); // 3 items in cart
          return user;
        }
      });

      // Scenario 3: Admin user workflow
      await createScenario({
        name: 'admin-workflow',
        setup: async () => {
          return await createUser({
            email: 'admin@example.com',
            role: 'admin',
            permissions: ['manage-users', 'manage-products', 'view-reports']
          });
        }
      });

      console.log('Scenario-based seed completed');
    }
    ```

    **Characteristics**:
    - Targeted test scenarios
    - Predictable test data
    - Easy to maintain
    - Good for specific feature testing
  </Accordion>
</AccordionGroup>

### Best Practices for Database Seeding

<CardGroup cols={2}>
  <Card title="Idempotent Seeds" icon="rotate">
    Make seeds rerunnable without errors - check if data exists before inserting
  </Card>

  <Card title="Fast Execution" icon="bolt">
    Optimize seed scripts with batch inserts and transactions
  </Card>

  <Card title="Deterministic Data" icon="fingerprint">
    Use fixed seeds for random data to ensure reproducibility
  </Card>

  <Card title="Environment-Aware" icon="circle-nodes">
    Use different seed strategies based on environment (dev, test, preview)
  </Card>

  <Card title="Version Control" icon="code-branch">
    Keep seed scripts in version control alongside migrations
  </Card>

  <Card title="Data Cleanup" icon="broom">
    Provide cleanup scripts to reset database state between tests
  </Card>
</CardGroup>

### Example: Complete Seeding Setup

Here's a production-ready example combining multiple approaches:

```javascript
// db/seed.js
const { Pool } = require('pg');

const pool = new Pool({
  connectionString: process.env.DATABASE_URL,
});

// Idempotent seed function
async function seedDatabase() {
  const client = await pool.connect();

  try {
    await client.query('BEGIN');

    // Check if already seeded
    const { rows } = await client.query('SELECT COUNT(*) FROM users');
    if (parseInt(rows[0].count) > 0) {
      console.log('Database already seeded, skipping...');
      await client.query('ROLLBACK');
      return;
    }

    // Determine seed strategy based on environment
    const env = process.env.APP_ENV || 'development';

    switch (env) {
      case 'preview':
        await seedMinimalData(client);
        break;
      case 'test':
        await seedRepresentativeData(client);
        break;
      case 'development':
        await seedDevelopmentData(client);
        break;
      default:
        console.log('No seeding needed for production');
        await client.query('ROLLBACK');
        return;
    }

    await client.query('COMMIT');
    console.log(`Database seeded successfully for ${env} environment`);

  } catch (error) {
    await client.query('ROLLBACK');
    console.error('Seed failed:', error);
    throw error;
  } finally {
    client.release();
  }
}

async function seedMinimalData(client) {
  // Insert minimal test data
  await client.query(`
    INSERT INTO users (email, name, role) VALUES
    ('admin@example.com', 'Admin User', 'admin'),
    ('user@example.com', 'Test User', 'user')
  `);

  await client.query(`
    INSERT INTO products (name, description, price) VALUES
    ('Test Product 1', 'Description 1', 10.00),
    ('Test Product 2', 'Description 2', 20.00)
  `);
}

async function seedRepresentativeData(client) {
  // More comprehensive data for testing
  // ... implementation
}

async function seedDevelopmentData(client) {
  // Development-specific data
  // ... implementation
}

// Run if called directly
if (require.main === module) {
  seedDatabase()
    .then(() => {
      console.log('Seeding completed');
      process.exit(0);
    })
    .catch((error) => {
      console.error('Seeding failed:', error);
      process.exit(1);
    });
}

module.exports = { seedDatabase };
```

### Automatic DNS

Qovery automatically generates unique domain names for each preview environment:

```
Pattern: {env-name}.{base-domain}

Examples:
- pr-123.preview.myapp.com
- feature-xyz.preview.myapp.com
- dev-john.dev.myapp.com
```

**Custom Domain Pattern**:
```yaml
domains:
  - name: ${QOVERY_ENVIRONMENT_NAME}.preview.myapp.com
    generate_certificate: true
```

---

## Approach 2: Advanced CI/CD Integration with E2E Testing

For teams requiring more control, custom workflows, and automated E2E testing, you can integrate ephemeral environments directly into your CI/CD pipeline. This approach is demonstrated in the comprehensive tutorial below.

<Info>
This tutorial shows how to build a complete E2E testing workflow using GitHub Actions, Qovery, and K6 load testing. The same principles apply to GitLab CI, CircleCI, Jenkins, and other CI/CD platforms.
</Info>

### Tutorial: Building E2E Testing Ephemeral Environments

This advanced tutorial demonstrates how to:
- Automatically create ephemeral environments for each pull request
- Run comprehensive E2E tests using K6
- Display test results in PR comments
- Automatically cleanup environments when PRs are closed

#### What You'll Build

<CardGroup cols={3}>
  <Card title="Automated Creation" icon="plus">
    Ephemeral environments created automatically when PR is labeled
  </Card>

  <Card title="E2E Testing" icon="vial">
    Run load tests and integration tests against live environments
  </Card>

  <Card title="Auto Cleanup" icon="trash">
    Environments destroyed automatically when PR closes
  </Card>
</CardGroup>

#### Architecture Overview

```mermaid
graph TB
    A[Pull Request Created] --> B[Build Container Image]
    B --> C[Push to ECR]
    C --> D[Label PR with 'e2e']
    D --> E[Clone Blueprint Environment]
    E --> F[Deploy Ephemeral Environment]
    F --> G[Run K6 E2E Tests]
    G --> H[Post Results to PR]
    I[PR Closed/Merged] --> J[Delete Ephemeral Environment]

    style A fill:#642DFF,color:#fff
    style E fill:#642DFF,color:#fff
    style G fill:#642DFF,color:#fff
    style J fill:#642DFF,color:#fff
```

#### Prerequisites

<Steps>
  <Step title="Required Tools">
    - **Qovery Account**: Sign up at [qovery.com](https://www.qovery.com)
    - **GitHub Repository**: For hosting your application code
    - **AWS Account**: For container registry (ECR) or use another registry
    - **Qovery CLI**: Install from [qovery.com/install](https://www.qovery.com/docs/using-qovery/interface/cli/)
  </Step>

  <Step title="GitHub Secrets">
    Configure the following secrets in your GitHub repository:

    - `QOVERY_API_TOKEN`: Your Qovery API token
    - `AWS_ACCESS_KEY_ID`: AWS credentials for ECR
    - `AWS_SECRET_ACCESS_KEY`: AWS credentials for ECR
    - `QOVERY_ORGANIZATION_ID`: Your Qovery organization ID
    - `QOVERY_PROJECT_ID`: Your Qovery project ID
    - `QOVERY_CLUSTER_ID`: Your Qovery cluster ID
  </Step>

  <Step title="Qovery Blueprint Environment">
    Create a base "blueprint" environment in Qovery that will be cloned for each PR:

    - Set up your application with proper configuration
    - Add database (PostgreSQL, MySQL, etc.)
    - Configure environment variables
    - Ensure it's working properly

    This blueprint will be the template for all ephemeral environments.
  </Step>
</Steps>

#### Step 1: Build and Push Container Image

First, create a GitHub Actions workflow to build your Docker image and push it to a container registry (AWS ECR in this example).

**Create `.github/workflows/build-and-push-image.yml`**:

```yaml
name: Build and Push Container Image

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]

jobs:
  run-unit-tests:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Run unit tests
        run: |
          # Add your unit test commands here
          echo "Running unit tests..."
          # npm test
          # pytest
          # go test ./...

  build-and-push-container:
    runs-on: ubuntu-latest
    needs: run-unit-tests
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: eu-west-3

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1
        with:
          mask-password: 'true'

      - name: Build, Tag, and push image to Amazon ECR
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: todo-app
          IMAGE_TAG: ${{ github.sha }}
        run: |
          docker build -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG .
          docker tag $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG $ECR_REGISTRY/$ECR_REPOSITORY:latest
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
```

<Info>
**What This Does**: Builds your Docker image on every push and pull request, then pushes it to Amazon ECR with both the commit SHA as a tag and the latest tag. This ensures you have a versioned image for each commit.
</Info>

#### Step 2: Create Ephemeral Environment and Run E2E Tests

Create a workflow that clones your blueprint environment, deploys it with the new container image, and runs E2E tests.

**Create `.github/workflows/pull-request-run-e2e-tests.yml`**:

```yaml
name: Pull Request E2E Tests

on:
  pull_request:
    types: [labeled]

jobs:
  create-ephemeral-environment:
    if: contains(github.event.pull_request.labels.*.name, 'e2e')
    runs-on: ubuntu-latest
    outputs:
      environment_name: ${{ steps.create-env.outputs.environment_name }}
      application_url: ${{ steps.deploy-env.outputs.application_url }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Install Qovery CLI
        run: |
          curl -s https://get.qovery.com | bash
          echo "$HOME/.qovery/bin" >> $GITHUB_PATH

      - name: Create Ephemeral Environment
        id: create-env
        env:
          QOVERY_API_TOKEN: ${{ secrets.QOVERY_API_TOKEN }}
          QOVERY_ORGANIZATION_ID: ${{ secrets.QOVERY_ORGANIZATION_ID }}
          QOVERY_PROJECT_ID: ${{ secrets.QOVERY_PROJECT_ID }}
          QOVERY_CLUSTER_ID: ${{ secrets.QOVERY_CLUSTER_ID }}
          BLUEPRINT_ENV_ID: ${{ secrets.QOVERY_BLUEPRINT_ENV_ID }}
        run: |
          # Set the environment name
          ENV_NAME="pr-${{ github.event.number }}"
          echo "environment_name=$ENV_NAME" >> $GITHUB_OUTPUT

          # Clone the blueprint environment
          qovery environment clone \
            --organization-id $QOVERY_ORGANIZATION_ID \
            --project-id $QOVERY_PROJECT_ID \
            --environment-id $BLUEPRINT_ENV_ID \
            --new-environment-name $ENV_NAME \
            --cluster-id $QOVERY_CLUSTER_ID

      - name: Update Application Container Tag
        env:
          QOVERY_API_TOKEN: ${{ secrets.QOVERY_API_TOKEN }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          ENV_NAME="pr-${{ github.event.number }}"

          # Get the application ID from the new environment
          APP_ID=$(qovery application list --environment $ENV_NAME --output json | jq -r '.[0].id')

          # Update the container image tag
          qovery application update $APP_ID \
            --tag $IMAGE_TAG

      - name: Deploy Ephemeral Environment
        id: deploy-env
        env:
          QOVERY_API_TOKEN: ${{ secrets.QOVERY_API_TOKEN }}
        run: |
          ENV_NAME="pr-${{ github.event.number }}"

          # Deploy the environment
          qovery environment deploy $ENV_NAME --wait

          # Get the application URL
          APP_URL=$(qovery application list --environment $ENV_NAME --output json | jq -r '.[0].url')
          echo "application_url=$APP_URL" >> $GITHUB_OUTPUT

      - name: Comment PR with Environment Info
        uses: actions/github-script@v6
        with:
          script: |
            const envName = 'pr-${{ github.event.number }}';
            const appUrl = '${{ steps.deploy-env.outputs.application_url }}';

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Ephemeral Environment Created\n\n` +
                    `**Environment**: ${envName}\n` +
                    `**URL**: ${appUrl}\n\n` +
                    `E2E tests are now running...`
            })

  run-e2e-tests:
    needs: create-ephemeral-environment
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Install K6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Run K6 E2E Tests
        id: k6-tests
        env:
          API_HOST: ${{ needs.create-ephemeral-environment.outputs.application_url }}
        run: |
          # Run K6 tests and save results
          k6 run tests/e2e/load-test.js --out json=test-results.json

          # Parse results for summary
          cat test-results.json | jq -s 'last' > test-summary.json

      - name: Post Test Results to PR
        if: always()
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const testResults = fs.readFileSync('test-summary.json', 'utf8');
            const results = JSON.parse(testResults);

            const passed = results.metrics.checks.values.passes || 0;
            const failed = results.metrics.checks.values.fails || 0;
            const total = passed + failed;
            const passRate = ((passed / total) * 100).toFixed(2);

            const body = `## E2E Test Results\n\n` +
              `**Status**: ${failed === 0 ? '✅ PASSED' : '❌ FAILED'}\n` +
              `**Total Checks**: ${total}\n` +
              `**Passed**: ${passed}\n` +
              `**Failed**: ${failed}\n` +
              `**Pass Rate**: ${passRate}%\n\n` +
              `**Duration**: ${results.metrics.iteration_duration.values.avg.toFixed(2)}ms (avg)\n` +
              `**HTTP Requests**: ${results.metrics.http_reqs.values.count}\n` +
              `**Failed Requests**: ${results.metrics.http_req_failed.values.passes || 0}\n\n` +
              `View full test results in the workflow run.`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            })

      - name: Upload Test Results
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: k6-test-results
          path: |
            test-results.json
            test-summary.json
```

<Warning>
**Important**: This workflow is triggered only when you add the `e2e` label to a pull request. This prevents creating ephemeral environments for every PR and helps control costs.
</Warning>

#### Step 3: K6 Load Test Script

Create a K6 test script to perform load testing against your ephemeral environment.

**Create `tests/e2e/load-test.js`**:

```javascript
import http from 'k6/http';
import { check, group, sleep, fail } from 'k6';
import { Rate } from 'k6/metrics';

// Custom metrics
const errorRate = new Rate('errors');

// Test configuration
export const options = {
  stages: [
    { duration: '30s', target: 20 },  // Ramp up to 20 users
    { duration: '2m', target: 100 },  // Ramp up to 100 users
    { duration: '1m', target: 50 },   // Scale down to 50 users
    { duration: '30s', target: 0 },   // Ramp down to 0 users
  ],
  thresholds: {
    'http_req_duration': ['p(95)<500'], // 95% of requests should be below 500ms
    'http_req_failed': ['rate<0.01'],   // Error rate should be less than 1%
    'errors': ['rate<0.1'],             // Custom error rate below 10%
  },
};

// Get API host from environment variable
const API_HOST = __ENV.API_HOST || 'http://localhost:3000';

// Helper function to generate UUID
function uuidv4() {
  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {
    const r = Math.random() * 16 | 0;
    const v = c === 'x' ? r : (r & 0x3 | 0x8);
    return v.toString(16);
  });
}

// Setup: Run once before tests
export function setup() {
  console.log(`Starting tests against: ${API_HOST}`);

  // Add test data to the database
  const params = {
    headers: {
      'Content-Type': 'application/json',
    },
  };

  const testItems = [];
  for (let i = 0; i < 20; i++) {
    const payload = JSON.stringify({
      title: `Test Item ${i + 1} - ${uuidv4()}`,
      completed: false,
    });

    const res = http.post(`${API_HOST}/api/todos`, payload, params);

    const success = check(res, {
      'setup: item created': (r) => r.status === 201 || r.status === 200,
    });

    if (success && res.json('id')) {
      testItems.push(res.json('id'));
    }
  }

  console.log(`Setup completed. Created ${testItems.length} test items.`);
  return { testItems };
}

// Main test function
export default function(data) {
  // Test 1: Get all todos
  group('Get All Todos', function() {
    const res = http.get(`${API_HOST}/api/todos`);

    const success = check(res, {
      'status is 200': (r) => r.status === 200,
      'response has todos': (r) => Array.isArray(r.json()) && r.json().length > 0,
      'response time < 500ms': (r) => r.timings.duration < 500,
    });

    errorRate.add(!success);
  });

  sleep(1);

  // Test 2: Create a new todo
  group('Create Todo', function() {
    const payload = JSON.stringify({
      title: `New Todo - ${uuidv4()}`,
      completed: false,
    });

    const params = {
      headers: {
        'Content-Type': 'application/json',
      },
    };

    const res = http.post(`${API_HOST}/api/todos`, payload, params);

    const success = check(res, {
      'status is 201 or 200': (r) => r.status === 201 || r.status === 200,
      'todo created with id': (r) => r.json('id') !== undefined,
      'response time < 1000ms': (r) => r.timings.duration < 1000,
    });

    errorRate.add(!success);

    // Store the created todo ID for later tests
    if (success && res.json('id')) {
      data.testItems = data.testItems || [];
      data.testItems.push(res.json('id'));
    }
  });

  sleep(1);

  // Test 3: Get a specific todo
  if (data.testItems && data.testItems.length > 0) {
    group('Get Single Todo', function() {
      const randomId = data.testItems[Math.floor(Math.random() * data.testItems.length)];
      const res = http.get(`${API_HOST}/api/todos/${randomId}`);

      const success = check(res, {
        'status is 200': (r) => r.status === 200,
        'todo has id': (r) => r.json('id') !== undefined,
        'response time < 300ms': (r) => r.timings.duration < 300,
      });

      errorRate.add(!success);
    });

    sleep(1);

    // Test 4: Update a todo
    group('Update Todo', function() {
      const randomId = data.testItems[Math.floor(Math.random() * data.testItems.length)];
      const payload = JSON.stringify({
        title: `Updated Todo - ${uuidv4()}`,
        completed: true,
      });

      const params = {
        headers: {
          'Content-Type': 'application/json',
        },
      };

      const res = http.put(`${API_HOST}/api/todos/${randomId}`, payload, params);

      const success = check(res, {
        'status is 200': (r) => r.status === 200,
        'todo updated': (r) => r.json('completed') === true,
        'response time < 500ms': (r) => r.timings.duration < 500,
      });

      errorRate.add(!success);
    });

    sleep(1);

    // Test 5: Delete a todo
    group('Delete Todo', function() {
      const randomId = data.testItems[Math.floor(Math.random() * data.testItems.length)];
      const res = http.del(`${API_HOST}/api/todos/${randomId}`);

      const success = check(res, {
        'status is 204 or 200': (r) => r.status === 204 || r.status === 200,
        'response time < 500ms': (r) => r.timings.duration < 500,
      });

      errorRate.add(!success);
    });
  }

  sleep(1);
}

// Teardown: Run once after all tests
export function teardown(data) {
  console.log('Tests completed.');
}

// Handle summary to output results
export function handleSummary(data) {
  return {
    'stdout': textSummary(data, { indent: ' ', enableColors: true }),
  };
}

function textSummary(data, options) {
  const indent = options.indent || '';
  const enableColors = options.enableColors || false;

  let summary = `\n${indent}Test Summary:\n`;
  summary += `${indent}  Total Requests: ${data.metrics.http_reqs.values.count}\n`;
  summary += `${indent}  Failed Requests: ${data.metrics.http_req_failed.values.passes || 0}\n`;
  summary += `${indent}  Request Duration (avg): ${data.metrics.http_req_duration.values.avg.toFixed(2)}ms\n`;
  summary += `${indent}  Request Duration (p95): ${data.metrics.http_req_duration.values['p(95)'].toFixed(2)}ms\n`;
  summary += `${indent}  Checks Passed: ${data.metrics.checks.values.passes}\n`;
  summary += `${indent}  Checks Failed: ${data.metrics.checks.values.fails}\n`;

  return summary;
}
```

<Accordion title="K6 Test Configuration Explained">
**Stages**: The test has 4 stages that simulate realistic user behavior:
- Stage 1 (30s): Ramp up from 0 to 20 virtual users
- Stage 2 (2m): Ramp up to 100 virtual users (peak load)
- Stage 3 (1m): Scale down to 50 users
- Stage 4 (30s): Ramp down to 0 users

**Thresholds**: Pass/fail criteria for the test:
- 95% of requests must complete in under 500ms
- Less than 1% of requests can fail
- Custom error rate must be below 10%

**Test Groups**: The script tests 5 key operations:
1. Get all todos
2. Create a new todo
3. Get a specific todo
4. Update a todo
5. Delete a todo

Each operation has specific checks to validate correctness and performance.
</Accordion>

#### Step 4: Destroy Ephemeral Environment

Create a workflow to automatically clean up the ephemeral environment when the PR is closed.

**Create `.github/workflows/pull-request-destroy-e2e-environment.yml`**:

```yaml
name: Destroy Ephemeral Environment

on:
  pull_request:
    types: [closed]

jobs:
  destroy-environment:
    runs-on: ubuntu-latest

    steps:
      - name: Install Qovery CLI
        run: |
          curl -s https://get.qovery.com | bash
          echo "$HOME/.qovery/bin" >> $GITHUB_PATH

      - name: Delete Ephemeral Environment
        env:
          QOVERY_API_TOKEN: ${{ secrets.QOVERY_API_TOKEN }}
        run: |
          ENV_NAME="pr-${{ github.event.number }}"

          # Check if environment exists
          if qovery environment list | grep -q "$ENV_NAME"; then
            echo "Deleting environment: $ENV_NAME"
            qovery environment delete $ENV_NAME --force
            echo "Environment deleted successfully"
          else
            echo "Environment $ENV_NAME does not exist, skipping deletion"
          fi

      - name: Comment PR with Cleanup Status
        uses: actions/github-script@v6
        with:
          script: |
            const envName = 'pr-${{ github.event.number }}';

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Ephemeral Environment Cleaned Up\n\n` +
                    `**Environment**: ${envName}\n` +
                    `**Status**: Deleted\n\n` +
                    `All resources have been cleaned up.`
            })
```

<Info>
**Automatic Cleanup**: This workflow triggers when a PR is closed (either merged or closed without merging), ensuring that ephemeral environments don't linger and incur unnecessary costs.
</Info>

#### Step 5: Testing the Workflow

<Steps>
  <Step title="Create a Pull Request">
    1. Make changes to your application code
    2. Push changes to a new branch
    3. Create a pull request

    The `build-and-push-image.yml` workflow will automatically build and push your container image.
  </Step>

  <Step title="Trigger Environment Creation">
    Add the `e2e` label to your pull request. This will trigger the `pull-request-run-e2e-tests.yml` workflow which will:

    1. Clone your blueprint environment
    2. Deploy the new container image
    3. Run K6 E2E tests
    4. Post results as PR comments
  </Step>

  <Step title="Review Test Results">
    Check the PR comments for:
    - Environment URL
    - E2E test results (pass/fail)
    - Performance metrics
    - Request statistics
  </Step>

  <Step title="Close the PR">
    When you close or merge the PR, the `pull-request-destroy-e2e-environment.yml` workflow will automatically delete the ephemeral environment.
  </Step>
</Steps>

#### Workflow Diagram

```mermaid
sequenceDiagram
    participant Dev as Developer
    participant GH as GitHub
    participant GHA as GitHub Actions
    participant ECR as Container Registry
    participant Qov as Qovery
    participant K6 as K6 Testing

    Dev->>GH: Create Pull Request
    GH->>GHA: Trigger build workflow
    GHA->>GHA: Run unit tests
    GHA->>ECR: Build & push image

    Dev->>GH: Add 'e2e' label
    GH->>GHA: Trigger E2E workflow
    GHA->>Qov: Clone blueprint environment
    Qov->>Qov: Create ephemeral env
    GHA->>Qov: Update container tag
    GHA->>Qov: Deploy environment
    Qov-->>GHA: Return deployment URL
    GHA->>GH: Comment with URL

    GHA->>K6: Run load tests
    K6->>Qov: Execute test scenarios
    Qov-->>K6: Return responses
    K6-->>GHA: Return test results
    GHA->>GH: Comment with results

    Dev->>GH: Close/Merge PR
    GH->>GHA: Trigger cleanup workflow
    GHA->>Qov: Delete environment
    Qov-->>GHA: Confirm deletion
    GHA->>GH: Comment cleanup status
```

### Advanced Configurations

<AccordionGroup>
  <Accordion title="Conditional Testing" icon="filter">
    **Only run E2E tests for specific paths**:

    ```yaml
    on:
      pull_request:
        types: [labeled]
        paths:
          - 'src/**'
          - 'api/**'
          - 'tests/**'
    ```

    **Skip E2E tests for documentation changes**:

    ```yaml
    on:
      pull_request:
        types: [labeled]
        paths-ignore:
          - 'docs/**'
          - '**.md'
          - '.github/**'
    ```
  </Accordion>

  <Accordion title="Multiple Test Suites" icon="list-check">
    Run different test suites based on labels:

    ```yaml
    jobs:
      smoke-tests:
        if: contains(github.event.pull_request.labels.*.name, 'smoke-test')
        steps:
          - run: k6 run tests/smoke.js

      load-tests:
        if: contains(github.event.pull_request.labels.*.name, 'load-test')
        steps:
          - run: k6 run tests/load.js

      integration-tests:
        if: contains(github.event.pull_request.labels.*.name, 'integration-test')
        steps:
          - run: k6 run tests/integration.js
    ```
  </Accordion>

  <Accordion title="Parallel Testing" icon="bolt">
    Run tests in parallel for faster feedback:

    ```yaml
    jobs:
      e2e-tests:
        strategy:
          matrix:
            test: [api, ui, integration, performance]
        steps:
          - name: Run ${{ matrix.test }} tests
            run: k6 run tests/${{ matrix.test }}.js
    ```
  </Accordion>

  <Accordion title="Slack Notifications" icon="bell">
    Send test results to Slack:

    ```yaml
    - name: Notify Slack
      uses: slackapi/slack-github-action@v1
      with:
        payload: |
          {
            "text": "E2E Tests ${{ job.status }}",
            "blocks": [
              {
                "type": "section",
                "text": {
                  "type": "mrkdwn",
                  "text": "*PR #${{ github.event.number }}*\nE2E Tests: ${{ job.status }}\nEnvironment: pr-${{ github.event.number }}\nURL: ${{ needs.create-ephemeral-environment.outputs.application_url }}"
                }
              }
            ]
          }
      env:
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
    ```
  </Accordion>

  <Accordion title="Cost Controls" icon="dollar-sign">
    **Limit concurrent ephemeral environments**:

    ```yaml
    jobs:
      create-environment:
        concurrency:
          group: ephemeral-environments
          cancel-in-progress: false
    ```

    **Auto-delete after time limit**:

    ```yaml
    - name: Schedule Auto-Deletion
      run: |
        # Delete environment after 24 hours
        qovery environment update pr-${{ github.event.number }} \
          --ttl 24h
    ```

    **Resource limits**:

    ```yaml
    - name: Set Resource Limits
      run: |
        qovery application update $APP_ID \
          --cpu 500m \
          --memory 1Gi \
          --instances-min 1 \
          --instances-max 2
    ```
  </Accordion>

  <Accordion title="Database Seeding" icon="seedling">
    Populate ephemeral environment with test data:

    ```yaml
    - name: Seed Test Data
      env:
        DATABASE_URL: ${{ steps.get-db-url.outputs.url }}
      run: |
        # Wait for database to be ready
        sleep 30

        # Run database migrations
        npm run db:migrate

        # Seed test data
        npm run db:seed
    ```
  </Accordion>
</AccordionGroup>

### Troubleshooting Common Issues

<AccordionGroup>
  <Accordion title="Environment Creation Fails" icon="circle-xmark">
    **Symptom**: Workflow fails when cloning blueprint environment

    **Common Causes**:
    - Invalid Qovery credentials
    - Blueprint environment doesn't exist
    - Insufficient permissions
    - Resource quota exceeded

    **Solutions**:
    ```yaml
    # Add error handling
    - name: Create Environment with Retry
      run: |
        for i in {1..3}; do
          if qovery environment clone ...; then
            echo "Environment created successfully"
            break
          else
            echo "Attempt $i failed, retrying..."
            sleep 10
          fi
        done
    ```

    - Verify all GitHub secrets are set correctly
    - Check Qovery API token permissions
    - Ensure blueprint environment is accessible
    - Review cluster resource limits
  </Accordion>

  <Accordion title="Tests Fail to Connect" icon="link-slash">
    **Symptom**: K6 tests cannot reach the ephemeral environment

    **Common Causes**:
    - Environment not fully deployed
    - Incorrect URL
    - DNS not propagated
    - Application health checks failing

    **Solutions**:
    ```yaml
    # Wait for deployment to be ready
    - name: Wait for Application
      run: |
        echo "Waiting for application to be ready..."
        for i in {1..30}; do
          if curl -f ${{ steps.deploy-env.outputs.application_url }}/health; then
            echo "Application is ready"
            break
          fi
          echo "Waiting... ($i/30)"
          sleep 10
        done
    ```

    - Add health check endpoint to your application
    - Increase wait time before running tests
    - Verify DNS and SSL certificate generation
  </Accordion>

  <Accordion title="High Test Failure Rate" icon="triangle-exclamation">
    **Symptom**: K6 tests report many failures

    **Common Causes**:
    - Database not seeded
    - Environment variables missing
    - Resource constraints
    - Load too high for environment

    **Solutions**:
    - Reduce K6 test load (fewer virtual users)
    - Ensure database seeding completes before tests
    - Check application logs for errors
    - Increase environment resources

    ```yaml
    # View application logs
    - name: Debug Application
      if: failure()
      run: |
        qovery log --environment pr-${{ github.event.number }} --tail 100
    ```
  </Accordion>

  <Accordion title="Environment Not Deleted" icon="trash">
    **Symptom**: Ephemeral environments persist after PR closes

    **Common Causes**:
    - Workflow not triggered
    - Qovery API error
    - Environment name mismatch

    **Solutions**:
    ```yaml
    # Add forced deletion
    - name: Force Delete Environment
      run: |
        qovery environment delete pr-${{ github.event.number }} \
          --force \
          --delete-database \
          --wait
    ```

    - Manually check for orphaned environments periodically
    - Set up TTL (time-to-live) in Qovery
    - Add scheduled cleanup workflow
  </Accordion>
</AccordionGroup>

### CI/CD Platform Alternatives

While this tutorial uses GitHub Actions, the same approach works with other CI/CD platforms:

<Tabs>
  <Tab title="GitLab CI">
    ```yaml
    # .gitlab-ci.yml
    stages:
      - build
      - test
      - cleanup

    create_environment:
      stage: test
      only:
        - merge_requests
      script:
        - curl -s https://get.qovery.com | bash
        - qovery environment clone --new-environment-name mr-$CI_MERGE_REQUEST_IID
        - qovery environment deploy mr-$CI_MERGE_REQUEST_IID

    run_tests:
      stage: test
      needs: [create_environment]
      script:
        - k6 run tests/e2e/load-test.js

    cleanup:
      stage: cleanup
      when: on_success
      script:
        - qovery environment delete mr-$CI_MERGE_REQUEST_IID --force
    ```
  </Tab>

  <Tab title="CircleCI">
    ```yaml
    # .circleci/config.yml
    version: 2.1

    jobs:
      create_environment:
        docker:
          - image: cimg/base:stable
        steps:
          - checkout
          - run:
              name: Install Qovery CLI
              command: curl -s https://get.qovery.com | bash
          - run:
              name: Create Ephemeral Environment
              command: |
                qovery environment clone --new-environment-name pr-$CIRCLE_PR_NUMBER
                qovery environment deploy pr-$CIRCLE_PR_NUMBER

      run_tests:
        docker:
          - image: grafana/k6:latest
        steps:
          - checkout
          - run:
              name: Run E2E Tests
              command: k6 run tests/e2e/load-test.js

    workflows:
      version: 2
      test:
        jobs:
          - create_environment
          - run_tests:
              requires:
                - create_environment
    ```
  </Tab>

  <Tab title="Jenkins">
    ```groovy
    // Jenkinsfile
    pipeline {
      agent any

      environment {
        QOVERY_API_TOKEN = credentials('qovery-api-token')
      }

      stages {
        stage('Create Environment') {
          steps {
            sh '''
              curl -s https://get.qovery.com | bash
              export PATH="$HOME/.qovery/bin:$PATH"
              qovery environment clone --new-environment-name pr-${CHANGE_ID}
              qovery environment deploy pr-${CHANGE_ID}
            '''
          }
        }

        stage('Run E2E Tests') {
          steps {
            sh 'k6 run tests/e2e/load-test.js'
          }
        }

        stage('Cleanup') {
          steps {
            sh 'qovery environment delete pr-${CHANGE_ID} --force'
          }
        }
      }
    }
    ```
  </Tab>
</Tabs>

---

## Cost Optimization Strategies

<CardGroup cols={2}>
  <Card title="Smaller Instances" icon="compress">
    Use reduced resources for ephemeral environments:
    - 500m CPU instead of 2 CPU
    - 1Gi memory instead of 4Gi
    - Single replica instead of multiple
  </Card>

  <Card title="Container Databases" icon="box">
    Use containerized databases instead of managed services:
    - PostgreSQL container vs RDS
    - MySQL container vs Cloud SQL
    - 70-90% cost savings
  </Card>

  <Card title="Auto-Cleanup" icon="clock">
    Aggressive cleanup policies:
    - Delete on PR close (immediate)
    - TTL of 24-48 hours max
    - Delete on inactivity (2-4 hours)
  </Card>

  <Card title="Spot Instances" icon="dollar-sign">
    Use spot/preemptible instances:
    - 60-80% cost reduction
    - Acceptable for ephemeral workloads
    - Configure cluster with spot nodes
  </Card>

  <Card title="Shared Resources" icon="share-nodes">
    Share resources when possible:
    - Single database with schemas
    - Shared cache instances
    - Shared monitoring stack
  </Card>

  <Card title="Limit Concurrency" icon="layer-group">
    Control concurrent environments:
    - Max 10 concurrent ephemeral envs
    - Queue additional requests
    - Priority based on labels
  </Card>
</CardGroup>

### Cost Tracking Example

```yaml
# Track costs with tags
tags:
  environment_type: ephemeral
  pr_number: ${{ github.event.number }}
  created_by: ${{ github.actor }}
  auto_cleanup: true
  cost_center: engineering
  ttl: 24h

# Monitor costs
budget:
  monthly_limit: 500  # USD
  alert_at: 400       # Alert at $400
  stop_at: 490        # Stop at $490
```

---

## Best Practices Summary

<Steps>
  <Step title="Start Simple">
    Begin with Qovery's automatic preview environments. Only move to advanced CI/CD integration when you need custom testing workflows.
  </Step>

  <Step title="Use Blueprint Environments">
    Create well-tested blueprint environments that serve as templates. This ensures consistency across all ephemeral environments.
  </Step>

  <Step title="Implement Strong Cleanup">
    Always have multiple cleanup mechanisms: automatic on PR close, TTL-based, and manual cleanup scripts.
  </Step>

  <Step title="Control Costs">
    Use smaller resources, container databases, spot instances, and limit concurrent environments to keep costs low.
  </Step>

  <Step title="Monitor and Alert">
    Track environment creation, test results, and costs. Set up alerts for failures and budget overruns.
  </Step>

  <Step title="Optimize Test Suites">
    Keep E2E tests focused and fast. Run comprehensive tests only when necessary (use labels to control).
  </Step>

  <Step title="Document for Your Team">
    Create clear documentation on how team members should use ephemeral environments and interpret test results.
  </Step>

  <Step title="Iterate and Improve">
    Continuously refine your workflows based on team feedback, test results, and cost data.
  </Step>
</Steps>

---

## Next Steps

<CardGroup cols={2}>
  <Card title="CI/CD Integration Guide" icon="rotate" href="/guides/advanced/ci-cd-integration">
    Deep dive into integrating Qovery with your CI/CD pipeline
  </Card>

  <Card title="CLI Reference" icon="terminal" href="/cli/commands">
    Complete CLI command reference for automation
  </Card>

  <Card title="API Documentation" icon="code" href="/api-reference">
    Use Qovery API for advanced automation scenarios
  </Card>

  <Card title="Multi-Environment Setup" icon="layer-group" href="/guides/use-cases/production-environment-management">
    Manage development, staging, and production environments
  </Card>
</CardGroup>
